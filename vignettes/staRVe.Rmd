---
title: "Spatio-temporal analysis of research vessel data"
author: "Ethan Lawler"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    fig_width: 6
    fig_height: 6
  rmarkdown::pdf_vignette:
    toc: true
    toc_depth: 3
    fig_width: 6
    fig_height: 6
vignette: >
  %\VignetteIndexEntry{Spatio-temporal analysis of research vessel data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(staRVe)
```


# Fitting a model

We'll use a survey of bird counts, included in the package as the `bird_survey` data (which is an `sf` object containing location data).

```
data(bird_survey)
bird_survey
```

The `bird_survey` data must first be transformed into an object of class `staRVe_model`, which we can do through the `prepare_staRVe_model` function.

We can specify a model using the formula interface (see `?lm` or `?glm`), although formulae work a bit differently in the `staRVe` package.
A typical formula for a `staRVe` model will look like
`Count ~ mean(Area+Elevation) + time(Year,type="ar1") + space("exponential")`.
Covariates, here `Area` and `Elevation`, affecting the mean of the response variable (in this case `Count`) can be given through the `mean(...)` function. The inside of `mean(...)` also follows the formula interface.

The temporal and spatial structures are also specified through the formula.
The time effect is determined through the `time(Year,type="ar1")` function.
You can only specify one variable to be your time variable, and the three `type`s available are `independent`, `ar1`, and `rw`.

The spatial covariance function is specified through the `space("matern",nu=1.5)` function, while the spatial locations are automatically retrieved from the data.
Explicity specifying the covariance function is not necessary.
By omitting the `space(...)` function an exponential covariance function is used.

The spatio-temporal dependence structure is specified through a \emph{directed acyclic graph}, which acts similar to a mesh. The nodes of this graph can be provided through a second `sf` object -- otherwise the default behaviour uses all the locations in the data as the nodes (if there are a large number of unique locations, the model preparation can take a long time).
The graph also needs edges connecting the nodes, which the package will create automatically.
The user must specify how many edges enter each node through the `n_neighbours` argument (default of 10) of `prepare_staRVe_model`.

For our example analysis, we will use the locations from the year 2000 as the nodes in our graph.
```{r}
nodes<- subset(bird_survey,year == 2000)
```

We can also specify a link function and response distribution.
As we have count data, we will use a Poisson distribution with a log link.
By default the model is not fit right away, but we will tell the package to fit the model with the argument `fit = T`.

```{r}
bird_model<- prepare_staRVe_model(
  cnt ~ time(year,type="ar1"),
  data = bird_survey,
  nodes = nodes,
  distribution = "poisson",
  link = "log",
  n = 5,
  fit = T)
```

The first thing we need to check is convergence of the model fit:

```{r}
convergence(bird_model)
```

A message saying something about `relative convergence` or `X-convergence` is a good sign.
If the message says `false converge` or `failed to converge`, then you should not trust the output of the model.
Of course, you should always look at the parameter and random effect estimates to make sure they make sense!

Let's start with the parameters.
```{r}
parameters(bird_model)
```
Here we can see the maximum likelihood estimates for our model.
The spatial covariance is the exponential covariance function as we specified earlier.
The spatial range parameter is
  rho = `r spatial_parameters(parameters(bird_model))["rho","par"]`, the spatio-temporal variance is
  tau = `r spatial_parameters(parameters(bird_model))["tau","par"]`, and the spatial smoothness parameter is fixed at nu = 0.5 for the exponential covariance.
The distance units for rho can be seen with
```{r}
settings(bird_model)
```
So the effective spatial range, i.e.~the distance at which locations are approximately uncorrelated, is `r spatial_parameters(parameters(bird_model))["rho","par"]` kilometres.

The temporal autoregressive parameters is
  phi = `r time_parameters(parameters(bird_model))["phi","par"]`.
All of the above spatial and temporal parameters are on the random effects scale, and could change drastically once transformed to the response scale.

Our response distribution is a Poisson distribution, which does not have any additional parameters (such as a variance or over-dispersion parameter) to estimate.
Similarly, we have no covariates in our model so the only fixed effect is a constant mean of
  mu = `r fixed_effects(parameters(bird_model))["mu","par"]` (before taking the link function to the response scale).

In addition to the parameters, you can also inspect the random effects and the in-sample predictions for the data, both of which are `sf` objects.
```{r}
random_effects(bird_model)
data(bird_model)
```





## Making predictions

To get a useful picture of the estimated spatial field (which is usually the "result" of interest), we'll have to make predictions over a raster grid.
We'll use the `raster` package here, but the `fasterize` package also works just as well.
The `predict_staRVe` function takes a fitted model (a `staRVe` object) and a raster and produces predictions over the raster for each year present in the model.
If desired you can also specify specific years for prediction.
Predictions are made for the spatial random field, the response at the link scale, and the response on the response scale.
Standard errors for prediction are also given for all three.

First, we'll define a (quite coarse) raster object from the geographical extent of our data:
```{r}
library(raster)
raster_to_predict<- raster(bird_survey,nrow=10,ncol=10)
raster_to_predict[]<- 0
```
Then we can predict on that raster:
```{r}
raster_prediction<- staRVe_predict(bird_model,raster_to_predict)
names(raster_prediction)
raster_prediction[[1]]
```

Since we the data we supplied to `prepare_staRVe_model` had multiple years, the resulting `raster_prediction` is a list with a raster object for each year.



# Some theory and some terminology

Now that we've seen how to fit a model, let's actually take a look at the model we're fitting and the pieces of data that live under the hood.

## A description of the model

For simplicity let's look at presence-absence data, using a logit link and Bernoulli response distribution.

A purely spatial model for presence-absence data without covariates can be described by the following equations:

\[
\begin{aligned}
    Y_{i}\left(\mathbf{s}\right) \vert w\left(\mathbf{s}\right)
        &\sim \text{Bernoulli}\left(
                    p\left(\mathbf{s}\right) =  \text{invlogit}\left[\mu + w\left(\mathbf{s}\right)\right]
                \right) \\
    W\left(\mathbf{S}\right)
        &\sim \text{NNGP}\left(0,~C\left(\mathbf{s}_{1},\mathbf{s}_{2}\right)\right)
\end{aligned}
\]

Let's piece this together step by step.
The first equation, called the observation equation, involves the $i$th data point at location $\mathbf{s}$, denoted $Y_{i}\left(\mathbf{s}\right)$, conditional on a random field value at the same location, given by $w\left(\mathbf{s}\right)$.
Since our data here is presence-absence data, our response variable $Y$ can be either a `0` for an absence or a `1` for presence.
Our Bernoulli distribution is governed by the probability of a presence, where that probability is given by the value
$\text{invlogit}\left[\mu + w\left(\mathbf{s}\right)\right].$
The invlogit function is our (inverse) link function, and takes values from $(-\infty,\infty)$ and transforms them to probabilities in the interval $(0,1)$.
Finally the parameter $\mu$ controls the overall (non-spatial) probability of a presence, while the random field $w\left(\mathbf{s}\right)$ controls how this probability changes with location.

The invlogit link function frees up the values of $\mu$ and $w\left(\mathbf{s}\right)$ to take on any value in the real numbers.
This freedom sets up the spatial random field $W\left(\mathbf{s}\right)$ to follow a Gaussian process.
The second equation above, called the process equation, describes this spatial random field.
(You might notice I use both upper-case $W$ and lower-case $w$ -- the big $W$ stands for a *random variable*; the small $w$ is an actual number that stands for a *realization* of $W$.)

A Gaussian process, shortened to GP, is written as
\[
    \text{GP}\left(\mu\left(\mathbf{s}\right),
        C\left(\mathbf{s}_{1},\mathbf{s}_{2}\right)
    \right).
\]
The parameter $\mu\left(\mathbf{s}\right)$ is a function which gives the mean of the spatial random field at each location.
In practice the mean function $\mu\left(\mathbf{s}\right)$ is fixed equal to 0 for identifiability concerns with the parameter $\mu$ in the observation equation.

The second parameter, $C\left(\mathbf{s}_{1},\mathbf{s}_{2}\right)$, is also a function.
This second function describes the covariance or correlation of the spatial random field as a function of distance.
If you give the covariance function two locations (or the distance between them), it will tell you if you should expect the random field at those two points to be similar.

While a Gaussian process is actually a random function over the entire spatial region of interest, it is common practice to estimate it only at a certain number of points.
These points are sometimes called knots or nodes.
In a slight abuse of terminology, when I refer to a Gaussian process that could be either the full function over the entire spatial region or just the knots.
However, when talking about the locations of a Gaussian process that refers specifically to the locations of the knots.

### Nearest neighbour Gaussian processes

Now, you might be wondering why the process equation above is written as
\[
W\left(\mathbf{S}\right)
    \sim \text{NNGP}\left(0,~C\left(\mathbf{s}_{1},\mathbf{s}_{2}\right)\right)
\]
with an NNGP instead of a GP.
To make the model actually work in a reasonable amount of time, our model uses a *nearest neighbour Gaussian process* instead of a vanilla *Gaussian process*.
The nearest neighbour Gaussian process, shortened to NNGP, needs much less computing power that the vanilla Gaussian process, but is a bit harder to fully understand.

To understand how a NNGP works compared a vanilla GP, consider two large parties with 100 people (or some other large number) in attendance each.
The hosts of the parties, Marc and Rachel, don't want anybody to feel left out, so they decide that they are going to introduce their guests to other guests.

Marc lives on Gaussian boulevard, and decides he wants to introduce every guest to every other guest.
That way, Marc argues, everybody will get to know each other.
After the 50th guest arrives, Marc has spent all of his time introducing people.
By the end of the night, Marc is exhausted and hasn't had any time to enjoy the party himself!
His guests, however, had a great time getting to know so many people.

Rachel, on the other hand, lives on nearest neighbour Gaussian avenue (these city planners should really think of shorter street names!).
Instead of introducing all of the guests to each other, Rachel decides she is only going to introduce people who live close to each other.
People who live close together, Rachel reasons, will probably benefit more from knowing each other, but people who live far apart might not get out of the relationship.
So Rachel only introduces each guest to the 5 people who live nearest to them.
At the end of Rachel's party, all the guests are *almost* as happy as they would have been at Marc's.
But(!) Rachel only spent a small amount of time introducing people and was able to enjoy her own party with her guests.

Translating this back from Marc and Rachel's parties, the 100 guests are 100 locations of special interest.
When trying to find the value of the random field at a specific location $\mathbf{s}$, Marc's Gaussian process method uses the information of all the 100 locations of interest to predict at $\mathbf{s}$.
Rachel's nearest neighbour Gaussian process method, on the other hand, uses only the 10 closest locations to $\mathbf{s}$ to predict at $\mathbf{s}$
Just as with the happiness of the guests, Rachel's nearest neighbour method works *almost* as well as Marc's vanilla Gaussian method.



There is one more technical detail in the nearest neighbour Gaussian process: information is only allowed to flow in one direction (e.g. from left to right).
To accomplish this, we create a so called directed acyclic graph (or DAG for short) which described both the flow of information and the factorization of the joint likelihood into conditional likelihoods.

In our model, each point represents a location for which we're finding the value of the spatial random field (the $w\left(\mathbf{s}\right)$).
We compute the covariance function once for each arrow in the graph.
We can also predict at a new location by finding the points on the graph closest to it and drawing arrows from those points to the new one.
Once we've predicted the value $w\left(\mathbf{s}\right)$ of the spatial random field at the location $\mathbf{s}$, we can plug it into the link function of the observation equation
\[
    p\left(\mathbf{s}\right) = \text{invlogit}\left[\mu+w\left(\mathbf{s}\right)\right]
\]
to predict the probability of a presence $p\left(\mathbf{s}\right)$ at the location $\mathbf{s}$.


## What actually happens when you fit a model?

The only data that we have to plug in to the model are the presence-absence observations $Y_{i}\left(\mathbf{s}\right)$.
Each observation is recorded as either a `0` for absence or a `1` for presence.

We have no direct data for the random spatial field $W\left(\mathbf{s}\right)$, but since the spatial field is connected to the observations through the link function we can still perform inference on the field.
The best way to think about the random spatial field is that, through the process equation, the random field gives the necessary spatial structure to the data.

Behind the scenes, we apply a technical trick in fitting the model.
By 'integrating out' the spatial random field, which in a more general form we call 'marginalizing over the random effects', we can introduce spatial structure to the observations without having to worry about the actual value of the spatial random field.
After finding the parameters using this marginal model, we then go back and estimate the value of random field.
